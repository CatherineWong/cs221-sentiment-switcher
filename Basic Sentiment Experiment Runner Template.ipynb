{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Experiment Runner Template\n",
    "10/23/16 - Basic pipeline to run sentiment experiments on the IMDB movie review corpus.\n",
    "Uses the IMDB dataset folder (http://ai.stanford.edu/~amaas/data/sentiment/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cathy/anaconda/lib/python2.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "imdb_folder_location = \"../aclImdb\" # Change this to wherever your imbd folder is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500_8.txt This movie was a sicky sweet cutesy romantic comedy, just the kind of movie I usually dislike but this one was just cute enough to keep me interested. It was really funny in one moment (probably why I liked it) and then just as serious in the next. Plus, it had Ellen in it and I've always had a soft spot for her.<br /><br />Basically, the owner of a book store, Helen (Kate Capshaw) finds a love letter in one of the old couches in her store. She thinks it is for her and goes crazy trying to figure out who sent it. She has kind of shut herself off from the world, so it really throws her for a loop. Eventually, almost everyone connected with her finds this letter and they are all getting mixed signals which creates some really funny moments.<br /><br />Like I said, I am usually not one for this type of movie but I really wound up enjoying it and recommend it highly. 8\n"
     ]
    }
   ],
   "source": [
    "def imdb_sentiment_reader(dataset_type='train', sentiment='both'):\n",
    "    \"\"\"\n",
    "    Iterator over the imdb dataset.\n",
    "    Args:\n",
    "        is_train: ['train', 'val', 'test] - whether to iterate over the train, val, or test sets.\n",
    "        sentiment: ['pos', 'neg', 'both']: whether to iterate over just the positive, just the\n",
    "                   negative, or both.\n",
    "    Returns: Iterator over (filename, movie_review, sentiment_score) tuples. \n",
    "    \"\"\"\n",
    "    subfolder = 'train' if dataset_type=='train' else 'test'\n",
    "    dataset_path = os.path.join(imdb_folder_location, subfolder)\n",
    "    if sentiment=='pos' or sentiment=='both':\n",
    "        # Sort by the index\n",
    "        filenames = sorted(os.listdir(os.path.join(dataset_path, 'pos')), \n",
    "                                key=lambda filename: int(filename.split('_')[0]))\n",
    "        # Take a slice if these are for val/test\n",
    "        if dataset_type == 'val' or dataset_type == 'test':\n",
    "            cutoff = int(math.ceil(len(filenames) * .2))\n",
    "            if dataset_type == 'val':\n",
    "                filenames = filenames[:cutoff]\n",
    "            else:\n",
    "                filenames = filenames[cutoff:]\n",
    "        for filename in filenames:\n",
    "            sentiment_score = int(filename.split('_')[1].split('.')[0])\n",
    "            with open(os.path.join(dataset_path, 'pos', filename)) as f:\n",
    "                review = f.read()\n",
    "            yield filename, review.decode('utf-8'), sentiment_score\n",
    "    if sentiment=='neg' or sentiment=='both':\n",
    "        # Sort by the index \n",
    "        filenames = sorted(os.listdir(os.path.join(dataset_path, 'neg')), \n",
    "                                key=lambda filename: int(filename.split('_')[0]))\n",
    "         # Take a slice if these are for val/test\n",
    "        if dataset_type == 'val' or dataset_type == 'test':\n",
    "            cutoff = int(math.ceil(len(filenames) * .2))\n",
    "            if dataset_type == 'val':\n",
    "                filenames = filenames[:cutoff]\n",
    "            else:\n",
    "                filenames = filenames[cutoff:]\n",
    "        for filename in filenames:\n",
    "            sentiment_score = int(filename.split('_')[1].split('.')[0])\n",
    "            with open(os.path.join(dataset_path, 'neg', filename)) as f:\n",
    "                review = f.read()\n",
    "            yield filename, review.decode('utf-8'), sentiment_score\n",
    "    \n",
    "# Example Usage\n",
    "for filename, review, score in imdb_sentiment_reader(dataset_type='test', sentiment='both'):\n",
    "    print filename, review, score\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nevaluator = DefaultEvaluator(verbose=True)\\nfor (filename, review, score) in imdb_sentiment_reader(dataset_type=\\'val\\', sentiment=\\'pos\\'): \\n    transformed = baseline_transform_func(filename, review, score)\\n    print review\\n    print transformed\\n    print \"Evaluation score: \" + str(evaluator.evaluate(filename, review, transformed, score))\\n    break\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DefaultEvaluator():\n",
    "    \"\"\"\n",
    "    Default evaluator for the sentiment IMDB problem.\n",
    "    Uses the default evaluation metric defined in the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        self.verbose=verbose\n",
    "        self.sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "        self.sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.build_bigram_lists()\n",
    "    \n",
    "    def get_bigrams(self, tokens):\n",
    "        # Gets bigrams from lowercased tokens\n",
    "        return [(tokens[i].lower(), tokens[i+1].lower()) for i in range(len(tokens) - 1)]\n",
    "    \n",
    "    def build_bigram_lists(self):\n",
    "        \"\"\"\n",
    "        Build lists of all positive and negative training bigrams.\n",
    "        \"\"\"\n",
    "        self.pos_bigrams = set()\n",
    "        print \"Building positive bigram list...\"\n",
    "        for index, (filename, review, score) in enumerate(\n",
    "            imdb_sentiment_reader(dataset_type='train', sentiment='pos')):\n",
    "            try:\n",
    "                tokens = word_tokenize(review)\n",
    "                self.pos_bigrams.update(self.get_bigrams(tokens))\n",
    "            except:\n",
    "                print \"Failed to tokenize: pos \" + filename\n",
    "            if self.verbose and index % 1000 == 0:\n",
    "                print \"Now on: \" + str(index)\n",
    "    \n",
    "        print \"Building negative bigram list...\"     \n",
    "        self.neg_bigrams = set()\n",
    "        for index, (filename, review, score) in enumerate(\n",
    "            imdb_sentiment_reader(dataset_type='train', sentiment='neg')):\n",
    "            try:\n",
    "                tokens = word_tokenize(review)\n",
    "                self.neg_bigrams.update(self.get_bigrams(tokens))\n",
    "            except:\n",
    "                print \"Failed to tokenize: neg \" + filename\n",
    "            if self.verbose and index % 1000 == 0:\n",
    "                print \"Now on: \" + str(index)\n",
    "                \n",
    "    def _convert_imdb_sent_score(self, imdb_score):\n",
    "        \"\"\"\n",
    "        Converts the IMDB sentiment score (on a 0-10 scale) to a binary (-1, 1) sentiment score.\n",
    "        \"\"\"\n",
    "        # IMDB metric: positive is >=7, negative is <= 4\n",
    "        if imdb_score >= 7:\n",
    "            return 1.0\n",
    "        elif imdb_score <= 4:\n",
    "            return -1.0\n",
    "        else:\n",
    "            raise Exception('IMDB score not >=7 or <= 4')\n",
    "    \n",
    "    def _convert_vader_sent_score(self, vader_score):\n",
    "        \"\"\"\n",
    "        Converts the vader score to its valence (negative scores are negative, positive are positive).\n",
    "        \"\"\"\n",
    "        return -1.0 if vader_score < 0 else 1.0\n",
    "    \n",
    "    def _get_sentiment_changed_score(self, old_score, new_review):\n",
    "        \"\"\"\n",
    "        Return 1 if sentiment changed, -1 if not. Uses the NLTK Vader sentiment analyzer.\n",
    "        \"\"\"\n",
    "        sentiment_score = self._convert_vader_sent_score(\n",
    "            self.sentiment_analyzer.polarity_scores(new_review)['compound'])\n",
    "        old_sent_score = self._convert_imdb_sent_score(old_score)\n",
    "        return 1.0 if (sentiment_score != old_sent_score) else -1.0\n",
    "    \n",
    "    def _get_sentence_score(self, old_review, new_review):\n",
    "        \"\"\"\n",
    "        Return a closeness score based on the similarity of number of sentences.\n",
    "        \"\"\"\n",
    "        num_old_sentences = len(self.sentence_tokenizer.tokenize(old_review))\n",
    "        num_new_sentences = len(self.sentence_tokenizer.tokenize(new_review))\n",
    "        return min(num_old_sentences/float(num_new_sentences), num_new_sentences/float(num_old_sentences))\n",
    "    \n",
    "    def _get_proper_noun_score(self, tagged_old_review, tagged_new_review):\n",
    "        \"\"\"\n",
    "        Returns a metric between 0-1 based on the overlap between proper nouns in the two reviews.\n",
    "        \"\"\"\n",
    "        proper_nouns_old = set([token for token in tagged_old_review if token[1] == 'NNP'])\n",
    "        proper_nouns_new = set([token for token in tagged_new_review if token[1] == 'NNP'])\n",
    "        num_overlap = len(proper_nouns_old.intersection(proper_nouns_new))\n",
    "        num_nouns = max(len(proper_nouns_old), len(proper_nouns_new))\n",
    "        if num_nouns == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return float(num_overlap) / max(len(proper_nouns_old), len(proper_nouns_new))\n",
    "    \n",
    "    def _get_pos_score(self, tagged_old_review, tagged_new_review):\n",
    "        \"\"\"\n",
    "        Returns a value between 0 and 1 based on the multiset overlap between the POS tags in \n",
    "        both reviews.\n",
    "        \"\"\"\n",
    "        pos_tags_old=[tagged_token[1] for tagged_token in tagged_old_review]\n",
    "        pos_tags_new=[tagged_token[1] for tagged_token in tagged_new_review]\n",
    "        intersection = Counter(pos_tags_old) & Counter(pos_tags_new)\n",
    "        num_overlap = sum(intersection.values())\n",
    "        num_pos = max(len(pos_tags_old), len(pos_tags_new))\n",
    "        if num_pos == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return float(num_overlap) / num_pos\n",
    "    \n",
    "    def _get_closeness_score(self, old_review, new_review, tokenized_old_review, tokenized_new_review):\n",
    "        \"\"\"\n",
    "        Return a value between 0 and 1 evaluating how similar the old_review is in lingustic \n",
    "        structure to the new one.\n",
    "        Calculated as (proper noun overlap) * (# sentences score) * (# POS score)\n",
    "        \"\"\"\n",
    "        tagged_old_review = nltk.pos_tag(tokenized_old_review)\n",
    "        tagged_new_review = nltk.pos_tag(tokenized_new_review)\n",
    "        \n",
    "        sentence_score = self._get_sentence_score(old_review, new_review)\n",
    "        proper_noun_score = self._get_proper_noun_score(tagged_old_review, tagged_new_review)\n",
    "        pos_score = self._get_pos_score(tagged_old_review, tagged_new_review)\n",
    "        return sentence_score * proper_noun_score * pos_score\n",
    "    \n",
    "    def _get_typical_language_score(self, tokenized_old_review, old_score, tokenized_new_review):\n",
    "        \"\"\"\n",
    "        Returns a value between 0 and 1 evaluating how similar the new_review is to existing reviews of \n",
    "        its desired sentiment.\n",
    "        Concretely, evaluates the fraction of bigrams in the new_review that appear in either \n",
    "        all other training data reviews of the same sentiment, or within the old_review.\n",
    "        \"\"\"\n",
    "        # Note: make sure to compare to other reviews that are the opposite of the old_score,\n",
    "        # NOT the vader score.\n",
    "        old_review_bigrams = set(self.get_bigrams(tokenized_old_review))\n",
    "        new_review_bigrams = self.get_bigrams(tokenized_new_review)\n",
    "        # Target sentiment is opposite of the old review sentiment\n",
    "        target_sentiment = -1 * self._convert_imdb_sent_score(old_score) \n",
    "        num_similar_bigrams = 0\n",
    "        for bigram in new_review_bigrams:\n",
    "            if (bigram in old_review_bigrams) or \\\n",
    "            (target_sentiment > 0 and bigram in self.pos_bigrams) or \\\n",
    "            (target_sentiment < 0 and bigram in self.neg_bigrams):\n",
    "                num_similar_bigrams += 1\n",
    "        if len(new_review_bigrams) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return num_similar_bigrams / float(len(new_review_bigrams))\n",
    "        \n",
    "    def evaluate(self, filename, old_review, new_review, old_score):\n",
    "        \"\"\"\n",
    "        Evaluation based on a sentiment changed score, closeness score, and 'typical language' score.\n",
    "        \"\"\"\n",
    "        tokenized_old = word_tokenize(old_review)\n",
    "        tokenized_new = word_tokenize(new_review)\n",
    "        sent_change = self._get_sentiment_changed_score(old_score, new_review)\n",
    "        closeness = self._get_closeness_score(old_review, new_review, tokenized_old, tokenized_new)\n",
    "        typicality = self._get_typical_language_score(tokenized_old, old_score, tokenized_new)\n",
    "        return sent_change * closeness * typicality\n",
    "\n",
    "# Example Usage - uses the baseline transformer defined below\n",
    "\"\"\"\n",
    "evaluator = DefaultEvaluator(verbose=True)\n",
    "for (filename, review, score) in imdb_sentiment_reader(dataset_type='val', sentiment='pos'): \n",
    "    transformed = baseline_transform_func(filename, review, score)\n",
    "    print review\n",
    "    print transformed\n",
    "    print \"Evaluation score: \" + str(evaluator.evaluate(filename, review, transformed, score))\n",
    "    break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating: 0\n",
      "Now evaluating: 1000\n",
      "Now evaluating: 2000\n",
      "Now evaluating: 3000\n",
      "Now evaluating: 4000\n",
      "Finished evaluating 4999 test reviews.\n",
      "Mean score: 5.5362\n"
     ]
    }
   ],
   "source": [
    "class ExperimentRunner():\n",
    "    \"\"\"\n",
    "    Runs a sentiment experiment runner experiment. \n",
    "    Trains on the training set, then iterates over the reviews in the test set,\n",
    "    transforming them using the transform_func and evaluating them using the eval_func.\n",
    "    \n",
    "    Outputs the average performance on the test set.\n",
    "    \n",
    "    Args:\n",
    "        train_reader: an iterator over (filename, review, score) tuples.\n",
    "        test_reader: an iterator over (filename, review, score) tuples.\n",
    "        transform_func: should take (filename, review, score) and return a transformed string review.\n",
    "        eval_func: should take (filename, old_review, new_review, old_sentiment_score) and return a score.\n",
    "        verbose: default = False\n",
    "    \"\"\"\n",
    "    def __init__(self, train_reader, test_reader, transform_func, evaluator=None, verbose=False):\n",
    "        self.train_reader = train_reader\n",
    "        self.test_reader = test_reader\n",
    "        self.transform_func = transform_func\n",
    "        if evaluator is None:\n",
    "            self.evaluator = DefaultEvaluator()\n",
    "            self.eval_func = self.evaluator.evaluate\n",
    "        else:\n",
    "            self.eval_func = evaluator.evaluate\n",
    "        self.verbose = verbose\n",
    "        self.scores = []\n",
    "    \n",
    "    def run_experiment(self):\n",
    "        # Iterate over the test set, transforming the reviews and evaluating them\n",
    "        for index, (filename, review, sent_score) in enumerate(self.test_reader):\n",
    "            if self.verbose and index % 5000 == 0:\n",
    "                print \"Now evaluating: \" + str(index)\n",
    "                # Print the running mean\n",
    "                print \"Current mean score: \" + str(np.mean(self.scores))\n",
    "            # Transform the review\n",
    "            transformed_review = self.transform_func(filename, review, sent_score)\n",
    "            # Evaluate the transformed review\n",
    "            new_score = self.eval_func(filename, review, transformed_review, sent_score)\n",
    "            self.scores.append(new_score)\n",
    "        if self.verbose:\n",
    "            print \"Finished evaluating \" + str(index) + \" test reviews.\"\n",
    "        print \"Mean score: \" + str(np.mean(self.scores))\n",
    "    \n",
    "# Example usage\n",
    "demo_train = imdb_sentiment_reader(dataset_type='train', sentiment='both')\n",
    "demo_test= imdb_sentiment_reader(dataset_type='val', sentiment='both')\n",
    "\n",
    "def demo_transform_func(filename, review, score):\n",
    "    return review\n",
    "\n",
    "class DemoEval:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def evaluate(self, filename, old_review, new_review, old_score):\n",
    "        return old_score\n",
    "\n",
    "demo_runner = ExperimentRunner(demo_train, demo_test, demo_transform_func, \n",
    "                               evaluator=DemoEval(), verbose=True)\n",
    "demo_runner.run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original review: \n",
      "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "Transformed review:\n",
      "I went and saw this movie not last night after being coaxed to by a not few friends of mine . I 'll admit that I was not reluctant to see it because from what I knew of Ashton Kutcher he was not only not able to do comedy . I was not wrong . Kutcher played the character of Jake Fischer not very not well , and Kevin Costner played Ben Randall with not such professionalism . The sign of a not good movie is that it can toy with our emotions . This one did not exactly that . The not entire theater ( which was sold out ) was overcome by laughter during the not first half of the movie , and were moved to tears during the not second half . While exiting the theater I not not not only saw not many women in tears , but not many not full grown men as not well , trying not desperately not not to let anyone see them crying . This movie was not great , and I suggest that you go see it before you judge .\n"
     ]
    }
   ],
   "source": [
    "def baseline_transform_func(filename, review, score):\n",
    "    \"\"\"\n",
    "    Baseline: returns a review with 'not' inserted in front of any identified adjectives/adverbs.\n",
    "    \"\"\"\n",
    "    tagged_review = nltk.pos_tag(word_tokenize(review))\n",
    "    transformed_review = []\n",
    "    for tagged_word in tagged_review:\n",
    "        if tagged_word[1] in ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']:\n",
    "            transformed_review.append('not')\n",
    "        transformed_review.append(tagged_word[0])\n",
    "    return \" \".join(transformed_review)\n",
    "# Example usage:\n",
    "for (filename, review, score) in imdb_sentiment_reader(dataset_type='val', sentiment='pos'):\n",
    "    print \"Original review: \"\n",
    "    print review\n",
    "    print \"Transformed review:\" \n",
    "    print baseline_transform_func(filename, review, score)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building positive bigram list...\n",
      "Now on: 0\n",
      "Now on: 1000\n",
      "Now on: 2000\n",
      "Now on: 3000\n",
      "Now on: 4000\n",
      "Now on: 5000\n",
      "Now on: 6000\n",
      "Now on: 7000\n",
      "Now on: 8000\n",
      "Now on: 9000\n",
      "Now on: 10000\n",
      "Now on: 11000\n",
      "Now on: 12000\n",
      "Building negative bigram list...\n",
      "Now on: 0\n",
      "Now on: 1000\n",
      "Now on: 2000\n",
      "Now on: 3000\n",
      "Now on: 4000\n",
      "Now on: 5000\n",
      "Now on: 6000\n",
      "Now on: 7000\n",
      "Now on: 8000\n",
      "Now on: 9000\n",
      "Now on: 10000\n",
      "Now on: 11000\n",
      "Now on: 12000\n",
      "Now evaluating: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8eb0ceccf6ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m baseline_runner = ExperimentRunner(train_reader, test_reader, baseline_transform_func, \n\u001b[1;32m      5\u001b[0m                                evaluator=default_evaluator, verbose=True)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbaseline_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-c5a141cd71ee>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtransformed_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Evaluate the transformed review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_review\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7d98777682ee>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, filename, old_review, new_review, old_score)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mtokenized_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0msent_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sentiment_changed_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mcloseness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_closeness_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_review\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_review\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mtypicality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_typical_language_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msent_change\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcloseness\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtypicality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7d98777682ee>\u001b[0m in \u001b[0;36m_get_closeness_score\u001b[0;34m(self, old_review, new_review, tokenized_old_review, tokenized_new_review)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \"\"\"\n\u001b[1;32m    113\u001b[0m         \u001b[0mtagged_old_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_old_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtagged_new_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_new_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0msentence_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sentence_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_review\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cathy/anaconda/lib/python2.7/site-packages/nltk/tag/__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cathy/anaconda/lib/python2.7/site-packages/nltk/tag/perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cathy/anaconda/lib/python2.7/site-packages/nltk/tag/perceptron.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mw_td_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_td_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cathy/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cathy/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Cathy/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_binget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_binget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBINGET\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_binget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_reader = imdb_sentiment_reader(dataset_type='train', sentiment='both')\n",
    "test_reader = imdb_sentiment_reader(dataset_type='val', sentiment='both')\n",
    "default_evaluator = DefaultEvaluator(verbose=True)\n",
    "baseline_runner = ExperimentRunner(train_reader, test_reader, baseline_transform_func, \n",
    "                               evaluator=default_evaluator, verbose=True)\n",
    "baseline_runner.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
